{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "# Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Ohter import\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Be sure to used Tensorflow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hasattr(tf, \"function\") # Be sure to use tensorflow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset: Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/kaggle-datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-cover.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fashio MNIST\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(images, targets), (images_test, targets_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Get only a subpart of the dataset\n",
    "images = images[:10000]\n",
    "targets = targets [:10000]\n",
    "\n",
    "# Reshape the dataset and convert to float\n",
    "images = images.reshape(-1, 784)\n",
    "images = images.astype(float)\n",
    "images_test = images_test.reshape(-1, 784)\n",
    "images_test = images_test.astype(float)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "images = scaler.fit_transform(images)\n",
    "images_test = scaler.transform(images_test)\n",
    "\n",
    "print(images.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot one of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \n",
    "                 \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]\n",
    "# Plot one image\n",
    "plt.imshow(np.reshape(images[11], (28, 28)), cmap=\"binary\")\n",
    "plt.title(targets_names[targets[11]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "![](images/simple_nn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Add the layers\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model_output = model.predict(images[0:1])\n",
    "print(model_output, targets[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(images, targets, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve = history.history[\"loss\"]\n",
    "acc_curve = history.history[\"accuracy\"]\n",
    "#acc_curve = history.history[\"acc\"]\n",
    "\n",
    "\n",
    "loss_val_curve = history.history[\"val_loss\"]\n",
    "acc_val_curve = history.history[\"val_accuracy\"]\n",
    "#acc_val_curve = history.history[\"val_acc\"]\n",
    "\n",
    "\n",
    "plt.plot(loss_curve, label=\"Train\")\n",
    "plt.plot(loss_val_curve, label=\"Val\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(acc_curve, label=\"Train\")\n",
    "plt.plot(acc_val_curve, label=\"Val\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(images_test, targets_test)\n",
    "print(\"Test Loss\", loss)\n",
    "print(\"Test Accuracy\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
